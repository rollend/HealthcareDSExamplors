{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\programdata\\anaconda3\\lib\\site-packages\\numpy\\core\\__init__.py:29: UserWarning: loaded more than 1 DLL from .libs:\n",
      "f:\\programdata\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.CSRRD7HKRKC3T3YXA7VY7TAZGLSWDKW6.gfortran-win_amd64.dll\n",
      "f:\\programdata\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.TXA6YQSD3GCQQC22GEQ54J2UDCXDXHWN.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..\\\\PythonModules\\\\'))                                           \n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "##import Bedrock_Client\n",
    "##import pyodbc\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##df = pd.read_sql_query('select * fROM ref.SHMI_Model_Predict_Statistics',Bedrock_Conn)\n",
    "import Pickle_Utility\n",
    "df =Pickle_Utility.read('shimi_predictor')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df.to_csv('shmi_predictor.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "PREDICTOR = 'Intercept'\n",
    "DIAGNOSIS_GROUP = '140'\n",
    "\n",
    "new_df = df[(df['PREDICTOR']==PREDICTOR)&(df['DIAGNOSIS_GROUP']==DIAGNOSIS_GROUP)][['Date','PARAMETER_ESTIMATE']].sort_values(by='Date')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.set_index('Date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PARAMETER_ESTIMATE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-05-13</th>\n",
       "      <td>-6.7492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-13</th>\n",
       "      <td>-6.7176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-13</th>\n",
       "      <td>-6.7659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-13</th>\n",
       "      <td>-6.7883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09-13</th>\n",
       "      <td>-6.7791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-13</th>\n",
       "      <td>-6.7582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-13</th>\n",
       "      <td>-6.7412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-13</th>\n",
       "      <td>-6.6527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-13</th>\n",
       "      <td>-6.6047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-13</th>\n",
       "      <td>-6.5791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-13</th>\n",
       "      <td>-6.5752</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            PARAMETER_ESTIMATE\n",
       "Date                          \n",
       "2019-05-13             -6.7492\n",
       "2019-06-13             -6.7176\n",
       "2019-07-13             -6.7659\n",
       "2019-08-13             -6.7883\n",
       "2019-09-13             -6.7791\n",
       "2019-10-13             -6.7582\n",
       "2019-11-13             -6.7412\n",
       "2019-12-13             -6.6527\n",
       "2020-01-13             -6.6047\n",
       "2020-02-13             -6.5791\n",
       "2020-03-13             -6.5752"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.ar_model import AR\n",
    "from statsmodels.tsa.ar_model import ARResults\n",
    "import numpy\n",
    " \n",
    "# create a difference transform of the dataset\n",
    "def difference(dataset):\n",
    "    diff = list()\n",
    "    for i in range(1, len(dataset)):\n",
    "        value = dataset[i] - dataset[i - 1]\n",
    "        diff.append(value)\n",
    "    return numpy.array(diff)\n",
    "df_train = new_df.drop(new_df.tail(1).index, inplace=False) \n",
    "# load dataset\n",
    "series = df_train.astype('float')\n",
    "X = difference(series.values)\n",
    "# fit model\n",
    "model = AR(X)\n",
    "model_fit = model.fit(maxlag=5, disp=False)\n",
    "# save model to file\n",
    "model_fit.save('ar_model.pkl')\n",
    "# save the differenced dataset\n",
    "numpy.save('ar_data.npy', X)\n",
    "# save the last ob\n",
    "numpy.save('ar_obs.npy', [series.values[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0316]\n",
      " [-0.0483]\n",
      " [-0.0224]\n",
      " [ 0.0092]\n",
      " [ 0.0209]\n",
      " [ 0.017 ]\n",
      " [ 0.0885]\n",
      " [ 0.048 ]\n",
      " [ 0.0256]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-6.5791])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[series.values[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.05365102 -0.2953882  -0.10225642  0.18276549 -0.0149401  -0.82798429]\n",
      "[[-6.5791]]\n"
     ]
    }
   ],
   "source": [
    "# load the AR model from file\n",
    "from statsmodels.tsa.ar_model import ARResults\n",
    "import numpy\n",
    "loaded = ARResults.load('ar_model.pkl')\n",
    "print(loaded.params)\n",
    "data = numpy.load('ar_data.npy')\n",
    "last_ob = numpy.load('ar_obs.npy')\n",
    "print(last_ob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: -6.539303\n"
     ]
    }
   ],
   "source": [
    "# load AR model from file and make a one-step prediction\n",
    "from statsmodels.tsa.ar_model import ARResults\n",
    "import numpy\n",
    "# load model\n",
    "model = ARResults.load('ar_model.pkl')\n",
    "data = numpy.load('ar_data.npy')\n",
    "last_ob = numpy.load('ar_obs.npy')\n",
    "# make prediction\n",
    "predictions = model.predict(start=len(data), end=len(data))\n",
    "# transform prediction\n",
    "yhat = predictions[0] + last_ob[0]\n",
    "print('Prediction: %f' % yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PARAMETER_ESTIMATE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-03-13</th>\n",
       "      <td>-6.5752</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           PARAMETER_ESTIMATE\n",
       "Date                         \n",
       "2020-03-13            -6.5752"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10   -6.551517\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\programdata\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:219: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  ' ignored when e.g. forecasting.', ValueWarning)\n",
      "f:\\programdata\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:576: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  ValueWarning)\n"
     ]
    }
   ],
   "source": [
    "# AR example\n",
    "from statsmodels.tsa.ar_model import AR\n",
    "from random import random\n",
    "# contrived dataset\n",
    "data = df_train.astype('float')\n",
    "# fit model\n",
    "model = AR(data)\n",
    "model_fit = model.fit()\n",
    "# make prediction\n",
    "yhat = model_fit.predict(len(data), len(data))\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10   -6.579215\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\programdata\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:219: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  ' ignored when e.g. forecasting.', ValueWarning)\n",
      "f:\\programdata\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:576: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  ValueWarning)\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.holtwinters import SimpleExpSmoothing\n",
    "from random import random\n",
    "# contrived dataset\n",
    "data = df_train.astype('float')\n",
    "# fit model\n",
    "model = SimpleExpSmoothing(data)\n",
    "model_fit = model.fit()\n",
    "# make prediction\n",
    "yhat = model_fit.predict(len(data), len(data))\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10   -6.579215\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\programdata\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:219: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  ' ignored when e.g. forecasting.', ValueWarning)\n",
      "f:\\programdata\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:576: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  ValueWarning)\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from random import random\n",
    "# contrived dataset\n",
    "data = df_train.astype('float')\n",
    "# fit model\n",
    "model = ExponentialSmoothing(data)\n",
    "model_fit = model.fit()\n",
    "# make prediction\n",
    "yhat = model_fit.predict(len(data), len(data))\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PARAMETER_ESTIMATE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-05-13</th>\n",
       "      <td>-6.7492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-13</th>\n",
       "      <td>-6.7176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-13</th>\n",
       "      <td>-6.7659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-13</th>\n",
       "      <td>-6.7883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09-13</th>\n",
       "      <td>-6.7791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-13</th>\n",
       "      <td>-6.7582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-13</th>\n",
       "      <td>-6.7412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-13</th>\n",
       "      <td>-6.6527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-13</th>\n",
       "      <td>-6.6047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-13</th>\n",
       "      <td>-6.5791</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            PARAMETER_ESTIMATE\n",
       "Date                          \n",
       "2019-05-13             -6.7492\n",
       "2019-06-13             -6.7176\n",
       "2019-07-13             -6.7659\n",
       "2019-08-13             -6.7883\n",
       "2019-09-13             -6.7791\n",
       "2019-10-13             -6.7582\n",
       "2019-11-13             -6.7412\n",
       "2019-12-13             -6.6527\n",
       "2020-01-13             -6.6047\n",
       "2020-02-13             -6.5791"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from multiprocessing import cpu_count\n",
    "from joblib import Parallel\n",
    "from joblib import delayed\n",
    "from warnings import catch_warnings\n",
    "from warnings import filterwarnings\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from pandas import read_csv\n",
    "from numpy import array\n",
    " \n",
    "# one-step Holt Winterâ€™s Exponential Smoothing forecast\n",
    "def exp_smoothing_forecast(history, config):\n",
    "\tt,d,s,p,b,r = config\n",
    "\t# define model\n",
    "\thistory = array(history)\n",
    "\tmodel = ExponentialSmoothing(history, trend=t, damped=d, seasonal=s, seasonal_periods=p)\n",
    "\t# fit model\n",
    "\tmodel_fit = model.fit(optimized=True, use_boxcox=b, remove_bias=r)\n",
    "\t# make one step forecast\n",
    "\tyhat = model_fit.predict(len(history), len(history))\n",
    "\treturn yhat[0]\n",
    " \n",
    "# root mean squared error or rmse\n",
    "def measure_rmse(actual, predicted):\n",
    "\treturn sqrt(mean_squared_error(actual, predicted))\n",
    " \n",
    "# split a univariate dataset into train/test sets\n",
    "def train_test_split(data, n_test):\n",
    "\treturn data[:-n_test], data[-n_test:]\n",
    " \n",
    "# walk-forward validation for univariate data\n",
    "def walk_forward_validation(data, n_test, cfg):\n",
    "\tpredictions = list()\n",
    "\t# split dataset\n",
    "\ttrain, test = train_test_split(data, n_test)\n",
    "\t# seed history with training dataset\n",
    "\thistory = [x for x in train]\n",
    "\t# step over each time-step in the test set\n",
    "\tfor i in range(len(test)):\n",
    "\t\t# fit model and make forecast for history\n",
    "\t\tyhat = exp_smoothing_forecast(history, cfg)\n",
    "\t\t# store forecast in list of predictions\n",
    "\t\tpredictions.append(yhat)\n",
    "\t\t# add actual observation to history for the next loop\n",
    "\t\thistory.append(test[i])\n",
    "\t# estimate prediction error\n",
    "\terror = measure_rmse(test, predictions)\n",
    "\treturn error\n",
    " \n",
    "# score a model, return None on failure\n",
    "def score_model(data, n_test, cfg, debug=False):\n",
    "\tresult = None\n",
    "\t# convert config to a key\n",
    "\tkey = str(cfg)\n",
    "\t# show all warnings and fail on exception if debugging\n",
    "\tif debug:\n",
    "\t\tresult = walk_forward_validation(data, n_test, cfg)\n",
    "\telse:\n",
    "\t\t# one failure during model validation suggests an unstable config\n",
    "\t\ttry:\n",
    "\t\t\t# never show warnings when grid searching, too noisy\n",
    "\t\t\twith catch_warnings():\n",
    "\t\t\t\tfilterwarnings(\"ignore\")\n",
    "\t\t\t\tresult = walk_forward_validation(data, n_test, cfg)\n",
    "\t\texcept:\n",
    "\t\t\terror = None\n",
    "\t# check for an interesting result\n",
    "\tif result is not None:\n",
    "\t\tprint(' > Model[%s] %.3f' % (key, result))\n",
    "\treturn (key, result)\n",
    " \n",
    "# grid search configs\n",
    "def grid_search(data, cfg_list, n_test, parallel=False):\n",
    "\tscores = None\n",
    "\tif parallel:\n",
    "\t\t# execute configs in parallel\n",
    "\t\texecutor = Parallel(n_jobs=cpu_count(), backend='multiprocessing')\n",
    "\t\ttasks = (delayed(score_model)(data, n_test, cfg) for cfg in cfg_list)\n",
    "\t\tscores = executor(tasks)\n",
    "\telse:\n",
    "\t\tscores = [score_model(data, n_test, cfg) for cfg in cfg_list]\n",
    "\t# remove empty results\n",
    "\tscores = [r for r in scores if r[1] != None]\n",
    "\t# sort configs by error, asc\n",
    "\tscores.sort(key=lambda tup: tup[1])\n",
    "\treturn scores\n",
    " \n",
    "# create a set of exponential smoothing configs to try\n",
    "def exp_smoothing_configs(seasonal=[None]):\n",
    "\tmodels = list()\n",
    "\t# define config lists\n",
    "\tt_params = ['add', 'mul', None]\n",
    "\td_params = [True, False]\n",
    "\ts_params = ['add', 'mul', None]\n",
    "\tp_params = seasonal\n",
    "\tb_params = [True, False]\n",
    "\tr_params = [True, False]\n",
    "\t# create config instances\n",
    "\tfor t in t_params:\n",
    "\t\tfor d in d_params:\n",
    "\t\t\tfor s in s_params:\n",
    "\t\t\t\tfor p in p_params:\n",
    "\t\t\t\t\tfor b in b_params:\n",
    "\t\t\t\t\t\tfor r in r_params:\n",
    "\t\t\t\t\t\t\tcfg = [t,d,s,p,b,r]\n",
    "\t\t\t\t\t\t\tmodels.append(cfg)\n",
    "\treturn models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Model[['add', True, None, 0, False, True]] 0.313\n",
      " > Model[['add', True, None, 0, False, False]] 0.008\n",
      " > Model[['add', True, None, 6, False, True]] 0.313\n",
      " > Model[['add', True, None, 6, False, False]] 0.008\n",
      " > Model[['add', True, None, 12, False, True]] 0.313\n",
      " > Model[['add', True, None, 12, False, False]] 0.008\n",
      " > Model[['add', False, None, 0, False, True]] 0.038\n",
      " > Model[['add', False, None, 0, False, False]] 0.034\n",
      " > Model[['add', False, None, 6, False, True]] 0.038\n",
      " > Model[['add', False, None, 6, False, False]] 0.034\n",
      " > Model[['add', False, None, 12, False, True]] 0.038\n",
      " > Model[['add', False, None, 12, False, False]] 0.034\n",
      " > Model[[None, False, 'add', 6, False, True]] 0.780\n",
      " > Model[[None, False, 'add', 6, False, False]] 0.048\n",
      " > Model[[None, False, None, 0, False, True]] 0.681\n",
      " > Model[[None, False, None, 0, False, False]] 0.026\n",
      " > Model[[None, False, None, 6, False, True]] 0.681\n",
      " > Model[[None, False, None, 6, False, False]] 0.026\n",
      " > Model[[None, False, None, 12, False, True]] 0.681\n",
      " > Model[[None, False, None, 12, False, False]] 0.026\n",
      "done\n",
      "['add', True, None, 0, False, False] 0.007673882387168263\n",
      "['add', True, None, 6, False, False] 0.007673882387168263\n",
      "['add', True, None, 12, False, False] 0.007673882387168263\n"
     ]
    }
   ],
   "source": [
    "data = df_train.astype('float').values\n",
    "\t# data split\n",
    "n_test = 1\n",
    "# model configs\n",
    "cfg_list = exp_smoothing_configs(seasonal=[0,6,12])\n",
    "# grid search\n",
    "\n",
    "#walk_forward_validation(data, n_test, cfg)\n",
    "\n",
    "scores = grid_search(data[:,0], cfg_list, n_test)\n",
    "print('done')\n",
    "# list top 3 configs\n",
    "for cfg, error in scores[:3]:\n",
    "    print(cfg, error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
